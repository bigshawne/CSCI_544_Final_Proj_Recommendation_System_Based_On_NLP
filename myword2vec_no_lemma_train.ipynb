{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7709fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd09f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aKOP4d8UuFoeShiopqOtBQ</td>\n",
       "      <td>[think, place, better, rating, location, bigge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VHfY59ctsugaOd4vVvUVMQ</td>\n",
       "      <td>[wonderful, staff, delicious, bbq, quick, fril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bf4J2wsJYWIpmmff2iZTDA</td>\n",
       "      <td>[yes, used, thelonious, monkfish, hipster, chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BXDFhzarvzkCfsm-6oQolw</td>\n",
       "      <td>[friends, came, watching, lovely, documentary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UqukowIJJh-THhVhlEUy4w</td>\n",
       "      <td>[like, think, boba, frequent, san, gabriel, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>JnnMBFQ60M4MKj5Jn5LyIw</td>\n",
       "      <td>[wary, bars, brighton, allston, undergrad, han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Z1lRuV7aA9I-LlD51qFlNQ</td>\n",
       "      <td>[husband, enjoyed, delightful, al, fresco, din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>qEuMDrWyLN49p1-i6zDsQA</td>\n",
       "      <td>[allure, trivia, night, cent, wings, strong, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>69XidCXVzOHgiQssXnZi5w</td>\n",
       "      <td>[came, dinner, last, week, commemorate, moving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>9yUAuiEFMrX6QnUq-lxgOw</td>\n",
       "      <td>[time, tried, place, meaning, come, months, ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_ID  \\\n",
       "0      aKOP4d8UuFoeShiopqOtBQ   \n",
       "1      VHfY59ctsugaOd4vVvUVMQ   \n",
       "2      bf4J2wsJYWIpmmff2iZTDA   \n",
       "3      BXDFhzarvzkCfsm-6oQolw   \n",
       "4      UqukowIJJh-THhVhlEUy4w   \n",
       "...                       ...   \n",
       "99995  JnnMBFQ60M4MKj5Jn5LyIw   \n",
       "99996  Z1lRuV7aA9I-LlD51qFlNQ   \n",
       "99997  qEuMDrWyLN49p1-i6zDsQA   \n",
       "99998  69XidCXVzOHgiQssXnZi5w   \n",
       "99999  9yUAuiEFMrX6QnUq-lxgOw   \n",
       "\n",
       "                                                  review  \n",
       "0      [think, place, better, rating, location, bigge...  \n",
       "1      [wonderful, staff, delicious, bbq, quick, fril...  \n",
       "2      [yes, used, thelonious, monkfish, hipster, chi...  \n",
       "3      [friends, came, watching, lovely, documentary,...  \n",
       "4      [like, think, boba, frequent, san, gabriel, be...  \n",
       "...                                                  ...  \n",
       "99995  [wary, bars, brighton, allston, undergrad, han...  \n",
       "99996  [husband, enjoyed, delightful, al, fresco, din...  \n",
       "99997  [allure, trivia, night, cent, wings, strong, k...  \n",
       "99998  [came, dinner, last, week, commemorate, moving...  \n",
       "99999  [time, tried, place, meaning, come, months, ho...  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"no_lemma_train.json\")\n",
    "data = json.load(f)\n",
    "data_items = data.items()\n",
    "data_list = list(data_items)\n",
    "df = pd.DataFrame(data_list,columns=[\"business_ID\",\"review\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8df0af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model with gensim\n",
    "dataset = df['review']\n",
    "sentence = [row for row in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf4c71",
   "metadata": {},
   "source": [
    "## 300 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c05cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233503102, 245526510)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models\n",
    "# Set the embedding size to be 300 and the window size to be 5. Can also consider a minimum word count of 1. \n",
    "w2v_model_300 = models.Word2Vec(min_count=1, window=5, vector_size=300)\n",
    "#build vocabulary table\n",
    "w2v_model_300.build_vocab(sentence, progress_per=100000)\n",
    "# train word2vec model\n",
    "w2v_model_300.train(sentence, total_examples=w2v_model_300.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a3d663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.741\n"
     ]
    }
   ],
   "source": [
    "# example_test: excellent ~ outstanding\n",
    "word_similarity1 = w2v_model_300.wv.similarity('outstanding','excellent')\n",
    "print(round(word_similarity1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78b3b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence length is:  534\n"
     ]
    }
   ],
   "source": [
    "# initialize the embeddings(with padding)\n",
    "print(\"Longest sentence length is: \",max([len(sent) for sent in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91ea6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71525\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(w2v_model_300.wv)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "011cc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab = list(set([str(word) for sent in sentence for word in sent]))\n",
    "\n",
    "tok_idx = {t: i for i,t in enumerate(vocab)}\n",
    "idx_tok = {i: t for i,t in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3487bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "count = 0\n",
    "for i, word in idx_tok.items():\n",
    "    if word in w2v_model_300.wv:\n",
    "        embedding_matrix[i] = w2v_model_300.wv[word]\n",
    "    else:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dbe8a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71525, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e1865c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = embedding_matrix.tolist()\n",
    "word_vec = {}\n",
    "for i, word in idx_tok.items():\n",
    "    word_vec[word] = t1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5d6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('300d_myword2vec_no_lemma_train.json', 'w') as json_out:\n",
    "    json_out.write(json.dumps(word_vec, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319aa713",
   "metadata": {},
   "source": [
    "## 200 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0df24bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233502204, 245526510)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the embedding size to be 200 and the window size to be 5. Can also consider a minimum word count of 1. \n",
    "w2v_model_200 = models.Word2Vec(min_count=1, window=5, vector_size=200)\n",
    "#build vocabulary table\n",
    "w2v_model_200.build_vocab(sentence, progress_per=100000)\n",
    "# train word2vec model\n",
    "w2v_model_200.train(sentence, total_examples=w2v_model_200.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c67e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789\n"
     ]
    }
   ],
   "source": [
    "# example_test: excellent ~ outstanding\n",
    "word_similarity2 = w2v_model_200.wv.similarity('outstanding','excellent')\n",
    "print(round(word_similarity2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05c4ce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71525\n"
     ]
    }
   ],
   "source": [
    "vocab_size1 = len(w2v_model_200.wv)\n",
    "print(vocab_size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75e99752",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix1 = np.zeros((vocab_size1, 200))\n",
    "count = 0\n",
    "for i, word in idx_tok.items():\n",
    "    if word in w2v_model_200.wv:\n",
    "        embedding_matrix1[i] = w2v_model_200.wv[word]\n",
    "    else:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bd7ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = embedding_matrix1.tolist()\n",
    "word_vec1 = {}\n",
    "for i, word in idx_tok.items():\n",
    "    word_vec1[word] = t2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64ff9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('200d_myword2vec_no_lemma_train.json', 'w') as json_out:\n",
    "    json_out.write(json.dumps(word_vec1, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04366896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
